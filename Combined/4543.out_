hendrixgpu07fl.unicph.domain
0
0 it number
learning rate: 1.0e-02
num_dense_layers: 1
num_dense_nodes: 10
activation: sigmoid
lamda: 0.1

Warning: 2000 points required, but 2025 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.027946 s

'compile' took 3.083797 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [6.14e-04, 2.15e-01, 1.23e-01]    [4.89e-04, 2.15e-01, 1.23e-01]    []  
2000      [1.45e-03, 1.53e-03, 7.18e-02]    [1.78e-03, 1.51e-03, 7.18e-02]    []  
4000      [2.57e-04, 4.77e-04, 7.14e-02]    [4.62e-04, 4.81e-04, 7.14e-02]    []  
6000      [1.99e-04, 5.06e-04, 7.13e-02]    [1.84e-04, 5.06e-04, 7.13e-02]    []  
8000      [2.43e-04, 4.76e-04, 7.12e-02]    [2.55e-04, 4.84e-04, 7.12e-02]    []  
10000     [4.66e-04, 4.61e-04, 7.12e-02]    [2.65e-04, 4.62e-04, 7.12e-02]    []  
Epoch 10000: early stopping

Best model at step 8000:
  train loss: 7.20e-02
  test loss: 7.20e-02
  test metric: []

Epoch 10000: saving model to Nomagnetic_5th_60/model-10000.ckpt ...

'train' took 9.218318 s

1 it number
learning rate: 6.9e-03
num_dense_layers: 8
num_dense_nodes: 19
activation: tanh
lamda: 0.07255540512037871

Warning: 2000 points required, but 2025 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.104615 s

'compile' took 37.828289 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [1.93e-01, 6.05e-01, 5.69e-02]    [1.81e-01, 6.05e-01, 5.69e-02]    []  
2000      [2.85e-03, 8.97e-03, 1.35e-01]    [2.06e-03, 8.97e-03, 1.35e-01]    []  
4000      [3.95e-03, 7.52e-03, 1.35e-01]    [4.26e-03, 7.52e-03, 1.35e-01]    []  
Epoch 4000: early stopping

Best model at step 2000:
  train loss: 1.46e-01
  test loss: 1.46e-01
  test metric: []

Epoch 4000: saving model to Nomagnetic_5th_61/model-4000.ckpt ...

'train' took 101.076799 s

2 it number
learning rate: 3.6e-04
num_dense_layers: 3
num_dense_nodes: 25
activation: sigmoid
lamda: 0.013065854800735549

Warning: 2000 points required, but 2025 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.052980 s

'compile' took 15.926559 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [5.73e-08, 2.33e+00, 1.09e-02]    [4.85e-08, 2.33e+00, 1.09e-02]    []  
2000      [5.98e-05, 3.38e-04, 2.82e-02]    [5.17e-05, 3.38e-04, 2.82e-02]    []  
4000      [8.97e-05, 3.97e-04, 2.81e-02]    [7.70e-05, 3.97e-04, 2.81e-02]    []  
6000      [9.39e-05, 4.05e-04, 2.80e-02]    [7.88e-05, 4.05e-04, 2.80e-02]    []  
8000      [9.66e-05, 4.04e-04, 2.80e-02]    [7.33e-05, 4.04e-04, 2.80e-02]    []  
10000     [1.64e-04, 5.94e-04, 2.62e-02]    [1.74e-04, 5.95e-04, 2.62e-02]    []  
12000     [5.39e-04, 5.11e-04, 1.10e-02]    [1.17e-03, 5.12e-04, 1.10e-02]    []  
14000     [2.72e-04, 1.78e-04, 9.67e-03]    [6.44e-04, 1.78e-04, 9.67e-03]    []  
16000     [1.41e-04, 9.07e-05, 9.46e-03]    [3.63e-04, 9.10e-05, 9.46e-03]    []  
18000     [1.15e-04, 8.17e-05, 9.41e-03]    [2.36e-04, 7.90e-05, 9.41e-03]    []  
20000     [6.07e-05, 4.06e-05, 9.41e-03]    [1.56e-04, 4.03e-05, 9.42e-03]    []  

Best model at step 20000:
  train loss: 9.52e-03
  test loss: 9.61e-03
  test metric: []

Epoch 20000: saving model to Nomagnetic_5th_62/model-20000.ckpt ...

'train' took 80.168147 s

3 it number
learning rate: 1.1e-04
num_dense_layers: 5
num_dense_nodes: 11
activation: tanh
lamda: 0.012538683368444242

Warning: 2000 points required, but 2025 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.073676 s

'compile' took 21.078023 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [3.68e-02, 8.60e-01, 9.85e-03]    [3.32e-02, 8.60e-01, 9.85e-03]    []  
2000      [4.16e-04, 5.37e-04, 2.68e-02]    [3.08e-04, 5.34e-04, 2.68e-02]    []  
4000      [2.46e-04, 5.28e-04, 2.65e-02]    [2.95e-04, 5.27e-04, 2.65e-02]    []  
6000      [2.21e-04, 5.80e-04, 2.59e-02]    [3.54e-04, 5.84e-04, 2.59e-02]    []  
8000      [6.17e-04, 1.56e-03, 1.58e-02]    [1.05e-03, 1.56e-03, 1.58e-02]    []  
10000     [4.27e-04, 1.05e-03, 1.00e-02]    [1.08e-03, 1.05e-03, 1.00e-02]    []  
12000     [3.23e-04, 5.48e-04, 9.19e-03]    [7.36e-04, 5.29e-04, 9.19e-03]    []  
14000     [2.25e-04, 2.92e-04, 9.03e-03]    [5.00e-04, 2.86e-04, 9.03e-03]    []  
16000     [4.49e-04, 1.86e-04, 9.02e-03]    [3.55e-04, 1.79e-04, 9.02e-03]    []  
Epoch 16000: early stopping

Best model at step 14000:
  train loss: 9.55e-03
  test loss: 9.82e-03
  test metric: []

Epoch 16000: saving model to Nomagnetic_5th_63/model-16000.ckpt ...

'train' took 107.950090 s

4 it number
learning rate: 1.6e-04
num_dense_layers: 5
num_dense_nodes: 2
activation: sin
lamda: 0.017635770689809285

Warning: 2000 points required, but 2025 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.076238 s

'compile' took 26.806357 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [2.30e+02, 9.91e-01, 1.40e-02]    [2.29e+02, 9.91e-01, 1.40e-02]    []  
2000      [4.27e-01, 1.34e-01, 2.63e-02]    [3.66e-01, 1.34e-01, 2.63e-02]    []  
4000      [1.14e-01, 2.24e-03, 3.78e-02]    [1.13e-01, 2.24e-03, 3.79e-02]    []  
6000      [2.22e-02, 3.62e-04, 3.86e-02]    [3.69e-02, 3.63e-04, 3.86e-02]    []  
8000      [1.08e-02, 4.28e-04, 3.84e-02]    [1.92e-02, 4.27e-04, 3.84e-02]    []  
10000     [4.95e-03, 4.49e-04, 3.84e-02]    [8.23e-03, 4.48e-04, 3.84e-02]    []  
12000     [1.86e-03, 4.54e-04, 3.83e-02]    [2.52e-03, 4.52e-04, 3.83e-02]    []  
14000     [6.79e-04, 4.58e-04, 3.83e-02]    [6.73e-04, 4.59e-04, 3.83e-02]    []  
16000     [2.52e-04, 4.56e-04, 3.83e-02]    [1.66e-04, 4.55e-04, 3.83e-02]    []  
18000     [1.13e-04, 4.53e-04, 3.83e-02]    [5.68e-05, 4.53e-04, 3.83e-02]    []  
20000     [3.38e-05, 4.53e-04, 3.83e-02]    [1.32e-05, 4.54e-04, 3.83e-02]    []  

Best model at step 20000:
  train loss: 3.88e-02
  test loss: 3.88e-02
  test metric: []

Epoch 20000: saving model to Nomagnetic_5th_64/model-20000.ckpt ...

'train' took 120.154390 s

5 it number
learning rate: 5.4e-02
num_dense_layers: 9
num_dense_nodes: 30
activation: sigmoid
lamda: 0.024761808027681763

Warning: 2000 points required, but 2025 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.126828 s

'compile' took 55.819561 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [4.82e-13, 8.94e-01, 2.01e-02]    [4.71e-13, 8.94e-01, 2.01e-02]    []  
2000      [5.54e-22, 8.68e-04, 5.33e-02]    [3.52e-22, 8.68e-04, 5.33e-02]    []  
4000      [3.99e-24, 8.68e-04, 5.33e-02]    [1.75e-24, 8.68e-04, 5.33e-02]    []  
Epoch 4000: early stopping

Best model at step 4000:
  train loss: 5.42e-02
  test loss: 5.42e-02
  test metric: []

Epoch 4000: saving model to Nomagnetic_5th_65/model-4000.ckpt ...

'train' took 164.168332 s

6 it number
learning rate: 4.7e-03
num_dense_layers: 6
num_dense_nodes: 24
activation: sin
lamda: 0.027247850801547492

Warning: 2000 points required, but 2025 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.088536 s

'compile' took 33.057840 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [6.07e-01, 2.66e+00, 2.30e-02]    [5.31e-01, 2.66e+00, 2.30e-02]    []  
2000      [9.10e-03, 1.26e-01, 2.15e-02]    [8.31e-03, 1.26e-01, 2.15e-02]    []  
4000      [1.85e-03, 1.71e-03, 3.59e-02]    [1.67e-03, 1.71e-03, 3.59e-02]    []  
6000      [5.66e-04, 1.98e-03, 2.59e-02]    [6.75e-04, 1.97e-03, 2.59e-02]    []  
8000      [2.47e-04, 2.93e-04, 1.95e-02]    [3.27e-04, 2.93e-04, 1.95e-02]    []  
10000     [1.03e-04, 2.37e-04, 1.93e-02]    [1.05e-04, 2.33e-04, 1.93e-02]    []  
12000     [1.49e-03, 4.99e-04, 1.94e-02]    [6.43e-04, 4.99e-04, 1.94e-02]    []  
Epoch 12000: early stopping

Best model at step 10000:
  train loss: 1.96e-02
  test loss: 1.96e-02
  test metric: []

Epoch 12000: saving model to Nomagnetic_5th_66/model-12000.ckpt ...

'train' took 144.570443 s

7 it number
learning rate: 1.3e-02
num_dense_layers: 10
num_dense_nodes: 2
activation: sin
lamda: 0.02901192881449209

Warning: 2000 points required, but 2025 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.145129 s

'compile' took 63.600376 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [1.24e-02, 1.22e+00, 2.29e-02]    [8.81e-03, 1.22e+00, 2.29e-02]    []  
2000      [9.42e-04, 2.66e-03, 5.64e-02]    [9.55e-04, 2.66e-03, 5.64e-02]    []  
4000      [1.72e-03, 2.19e-03, 5.66e-02]    [1.46e-03, 2.21e-03, 5.66e-02]    []  
Epoch 4000: early stopping

Best model at step 2000:
  train loss: 6.00e-02
  test loss: 6.01e-02
  test metric: []

Epoch 4000: saving model to Nomagnetic_5th_67/model-4000.ckpt ...

'train' took 181.875195 s

8 it number
learning rate: 2.5e-03
num_dense_layers: 4
num_dense_nodes: 25
activation: sin
lamda: 0.011153893091407734

Warning: 2000 points required, but 2025 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.062221 s

'compile' took 21.674336 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [1.34e-01, 1.79e+00, 8.96e-03]    [1.27e-01, 1.79e+00, 8.96e-03]    []  
2000      [4.78e-04, 2.85e-04, 8.81e-03]    [5.20e-04, 2.85e-04, 8.81e-03]    []  
4000      [2.69e-04, 8.53e-05, 8.08e-03]    [2.83e-04, 8.67e-05, 8.08e-03]    []  
6000      [2.16e-04, 8.50e-05, 8.02e-03]    [1.74e-04, 8.40e-05, 8.02e-03]    []  
8000      [8.59e-03, 1.11e-03, 8.09e-03]    [3.49e-03, 1.11e-03, 8.09e-03]    []  
Epoch 8000: early stopping

Best model at step 6000:
  train loss: 8.32e-03
  test loss: 8.28e-03
  test metric: []

Epoch 8000: saving model to Nomagnetic_5th_68/model-8000.ckpt ...

'train' took 105.294726 s

9 it number
learning rate: 4.8e-01
num_dense_layers: 7
num_dense_nodes: 28
activation: tanh
lamda: 0.09447169863034377

Warning: 2000 points required, but 2025 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.106280 s

'compile' took 36.656530 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [7.47e+00, 1.30e+00, 7.47e-02]    [3.37e+00, 1.30e+00, 7.47e-02]    []  
2000      [nan, nan, nan]                   [nan, nan, nan]                   []  

Best model at step 0:
  train loss: 8.85e+00
  test loss: 4.75e+00
  test metric: []

Epoch 2000: saving model to Nomagnetic_5th_69/model-2000.ckpt ...

'train' took 146.671200 s

10 it number
learning rate: 2.9e-03
num_dense_layers: 3
num_dense_nodes: 13
activation: tanh
lamda: 0.03978604897061095

Warning: 2000 points required, but 2025 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.044081 s

'compile' took 22.172282 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [2.76e-01, 1.19e+00, 3.13e-02]    [3.13e-01, 1.20e+00, 3.13e-02]    []  
2000      [6.87e-04, 9.69e-04, 2.86e-02]    [1.19e-03, 9.85e-04, 2.86e-02]    []  
4000      [6.11e-04, 3.46e-04, 2.86e-02]    [3.78e-04, 3.23e-04, 2.86e-02]    []  
6000      [1.62e-03, 1.17e-03, 2.83e-02]    [1.29e-03, 1.14e-03, 2.84e-02]    []  
Epoch 6000: early stopping

Best model at step 4000:
  train loss: 2.95e-02
  test loss: 2.93e-02
  test metric: []

Epoch 6000: saving model to Nomagnetic_5th_610/model-6000.ckpt ...

'train' took 110.122555 s

11 it number
learning rate: 3.2e-02
num_dense_layers: 1
num_dense_nodes: 30
activation: sigmoid
lamda: 0.1

Warning: 2000 points required, but 2025 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.027362 s

'compile' took 6.580408 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [3.36e-03, 2.20e+00, 8.35e-02]    [3.22e-03, 2.20e+00, 8.35e-02]    []  
2000      [1.87e-03, 2.09e-03, 6.93e-02]    [2.26e-03, 2.09e-03, 6.93e-02]    []  
4000      [1.62e-03, 1.25e-03, 6.99e-02]    [1.24e-03, 1.25e-03, 6.99e-02]    []  
6000      [2.74e-04, 1.03e-03, 6.96e-02]    [4.62e-04, 1.03e-03, 6.96e-02]    []  
8000      [9.26e-04, 9.81e-04, 6.97e-02]    [1.23e-03, 9.81e-04, 6.97e-02]    []  
Epoch 8000: early stopping

Best model at step 6000:
  train loss: 7.09e-02
  test loss: 7.11e-02
  test metric: []

Epoch 8000: saving model to Nomagnetic_5th_611/model-8000.ckpt ...

'train' took 80.809930 s

12 it number
learning rate: 9.0e-04
num_dense_layers: 10
num_dense_nodes: 1
activation: sigmoid
lamda: 0.1

Warning: 2000 points required, but 2025 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.122606 s

'compile' took 64.421468 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [1.22e-17, 2.39e-01, 1.27e-01]    [8.65e-18, 2.39e-01, 1.27e-01]    []  
2000      [3.97e-17, 1.23e-02, 1.97e-01]    [4.05e-17, 1.23e-02, 1.97e-01]    []  
4000      [1.06e-16, 1.23e-02, 1.97e-01]    [1.11e-16, 1.23e-02, 1.97e-01]    []  
Epoch 4000: early stopping

Best model at step 4000:
  train loss: 2.09e-01
  test loss: 2.09e-01
  test metric: []

Epoch 4000: saving model to Nomagnetic_5th_612/model-4000.ckpt ...

'train' took 219.384135 s

13 it number
learning rate: 4.2e-02
num_dense_layers: 10
num_dense_nodes: 1
activation: sigmoid
lamda: 0.01

Warning: 2000 points required, but 2025 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.155109 s

'compile' took 72.315952 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [3.43e-18, 9.54e-01, 7.96e-03]    [3.52e-18, 9.54e-01, 7.96e-03]    []  
2000      [1.14e-19, 1.46e-04, 2.19e-02]    [1.17e-19, 1.46e-04, 2.19e-02]    []  
4000      [1.38e-19, 1.46e-04, 2.19e-02]    [1.40e-19, 1.46e-04, 2.19e-02]    []  
Epoch 4000: early stopping

Best model at step 4000:
  train loss: 2.21e-02
  test loss: 2.21e-02
  test metric: []

Epoch 4000: saving model to Nomagnetic_5th_613/model-4000.ckpt ...

'train' took 238.073053 s

14 it number
learning rate: 6.0e-03
num_dense_layers: 2
num_dense_nodes: 19
activation: sigmoid
lamda: 0.05099111561396138

Warning: 2000 points required, but 2025 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.060786 s

'compile' took 15.089139 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [3.89e-05, 1.46e+00, 3.76e-02]    [3.77e-05, 1.46e+00, 3.76e-02]    []  
2000      [1.27e-03, 3.69e-03, 3.74e-02]    [1.87e-03, 3.69e-03, 3.74e-02]    []  
4000      [2.73e-04, 7.25e-04, 3.59e-02]    [5.27e-04, 7.29e-04, 3.59e-02]    []  
6000      [3.95e-04, 4.20e-04, 3.61e-02]    [5.22e-04, 4.19e-04, 3.61e-02]    []  
8000      [9.68e-04, 4.72e-04, 3.60e-02]    [8.29e-04, 4.68e-04, 3.60e-02]    []  
Epoch 8000: early stopping

Best model at step 6000:
  train loss: 3.69e-02
  test loss: 3.70e-02
  test metric: []

Epoch 8000: saving model to Nomagnetic_5th_614/model-8000.ckpt ...

'train' took 120.340919 s

[0.002469218272788538, 4, 25, 'sin', 0.011153893091407734]
