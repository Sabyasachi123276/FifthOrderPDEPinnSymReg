hendrixgpu02fl.unicph.domain
0
0 it number
learning rate: 1.0e-02
num_dense_layers: 1
num_dense_nodes: 10
activation: sigmoid
lamda: 0.1

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.025423 s

'compile' took 2.789307 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [8.38e-03, 9.17e-01, 1.26e-02]    [7.33e-03, 9.17e-01, 1.26e-02]    []  
2000      [2.76e-03, 3.70e-03, 1.74e-02]    [3.76e-03, 3.70e-03, 1.74e-02]    []  
4000      [2.27e-03, 1.05e-03, 1.32e-02]    [2.33e-03, 1.05e-03, 1.32e-02]    []  
6000      [1.58e-03, 6.91e-04, 1.33e-02]    [1.19e-03, 6.91e-04, 1.33e-02]    []  
8000      [6.77e-04, 6.94e-04, 1.33e-02]    [6.59e-04, 6.94e-04, 1.33e-02]    []  
10000     [4.62e-04, 8.00e-04, 1.31e-02]    [5.71e-04, 8.00e-04, 1.31e-02]    []  
12000     [4.00e-04, 8.02e-04, 1.31e-02]    [6.58e-04, 8.02e-04, 1.31e-02]    []  
14000     [2.07e-04, 8.69e-04, 1.30e-02]    [3.96e-04, 8.69e-04, 1.30e-02]    []  
16000     [3.72e-04, 9.27e-04, 1.29e-02]    [6.05e-04, 9.27e-04, 1.29e-02]    []  
Epoch 16000: early stopping

Best model at step 14000:
  train loss: 1.40e-02
  test loss: 1.42e-02
  test metric: []

'train' took 10.025581 s

1 it number
learning rate: 6.9e-03
num_dense_layers: 8
num_dense_nodes: 19
activation: tanh
lamda: 0.07255540512037871

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.081123 s

'compile' took 29.671501 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [7.14e-01, 1.23e+00, 1.04e-02]    [1.71e+00, 1.23e+00, 1.04e-02]    []  
2000      [1.94e-06, 3.54e-03, 1.02e-01]    [2.25e-06, 3.54e-03, 1.02e-01]    []  
4000      [5.92e-11, 6.59e-03, 9.83e-02]    [1.48e-11, 6.59e-03, 9.83e-02]    []  
6000      [5.38e-03, 9.10e-03, 7.93e-02]    [1.01e-02, 9.10e-03, 7.93e-02]    []  
8000      [2.94e-08, 6.59e-03, 9.83e-02]    [1.01e-08, 6.59e-03, 9.83e-02]    []  
Epoch 8000: early stopping

Best model at step 6000:
  train loss: 9.38e-02
  test loss: 9.85e-02
  test metric: []

'train' took 96.620678 s

2 it number
learning rate: 3.6e-04
num_dense_layers: 3
num_dense_nodes: 25
activation: sigmoid
lamda: 0.013065854800735549

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.041070 s

'compile' took 12.665064 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [7.34e-05, 2.61e+00, 3.67e-03]    [7.33e-05, 2.61e+00, 3.67e-03]    []  
2000      [5.77e-05, 4.13e-04, 1.91e-02]    [5.15e-05, 4.13e-04, 1.91e-02]    []  
4000      [7.86e-05, 4.75e-04, 1.90e-02]    [6.95e-05, 4.75e-04, 1.90e-02]    []  
6000      [8.36e-05, 4.88e-04, 1.90e-02]    [7.30e-05, 4.88e-04, 1.90e-02]    []  
8000      [8.69e-05, 4.88e-04, 1.90e-02]    [7.17e-05, 4.88e-04, 1.90e-02]    []  
10000     [1.44e-04, 4.95e-04, 1.88e-02]    [1.15e-04, 4.95e-04, 1.88e-02]    []  
12000     [4.41e-04, 1.12e-03, 8.76e-03]    [1.21e-03, 1.12e-03, 8.76e-03]    []  
14000     [4.12e-04, 3.77e-04, 2.28e-03]    [1.12e-03, 3.77e-04, 2.28e-03]    []  
16000     [2.48e-04, 1.73e-04, 1.94e-03]    [6.64e-04, 1.73e-04, 1.94e-03]    []  
18000     [1.34e-04, 1.07e-04, 1.87e-03]    [3.78e-04, 1.07e-04, 1.87e-03]    []  
20000     [1.02e-04, 8.32e-05, 1.86e-03]    [2.79e-04, 8.32e-05, 1.86e-03]    []  

Best model at step 20000:
  train loss: 2.05e-03
  test loss: 2.22e-03
  test metric: []

'train' took 58.988863 s

3 it number
learning rate: 1.1e-04
num_dense_layers: 5
num_dense_nodes: 11
activation: tanh
lamda: 0.012538683368444242

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.055948 s

'compile' took 18.462350 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [1.34e+01, 1.30e+00, 3.22e-03]    [7.68e+00, 1.30e+00, 3.22e-03]    []  
2000      [7.04e-03, 2.19e-03, 1.90e-02]    [4.43e-03, 2.19e-03, 1.90e-02]    []  
4000      [9.31e-04, 5.61e-04, 1.89e-02]    [1.05e-03, 5.61e-04, 1.89e-02]    []  
6000      [3.13e-04, 4.07e-04, 1.86e-02]    [5.62e-04, 4.07e-04, 1.86e-02]    []  
8000      [2.25e-04, 3.97e-04, 1.84e-02]    [2.36e-04, 3.97e-04, 1.84e-02]    []  
10000     [2.00e-04, 3.90e-04, 1.81e-02]    [1.57e-04, 3.90e-04, 1.81e-02]    []  
12000     [2.52e-04, 4.23e-04, 1.75e-02]    [3.04e-04, 4.23e-04, 1.75e-02]    []  
14000     [6.54e-04, 8.24e-04, 5.46e-03]    [1.29e-03, 8.24e-04, 5.46e-03]    []  
16000     [4.66e-04, 4.84e-04, 2.30e-03]    [9.91e-04, 4.84e-04, 2.30e-03]    []  
18000     [3.58e-04, 2.73e-04, 1.87e-03]    [8.44e-04, 2.73e-04, 1.87e-03]    []  
20000     [3.16e-04, 1.98e-04, 1.79e-03]    [7.69e-04, 1.98e-04, 1.79e-03]    []  

Best model at step 20000:
  train loss: 2.30e-03
  test loss: 2.76e-03
  test metric: []

'train' took 93.519536 s

4 it number
learning rate: 1.6e-04
num_dense_layers: 5
num_dense_nodes: 2
activation: sin
lamda: 0.017635770689809285

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.061168 s

'compile' took 21.744610 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [6.73e+02, 1.64e+00, 5.26e-03]    [3.78e+02, 1.64e+00, 5.26e-03]    []  
2000      [3.16e+00, 1.82e+00, 1.98e-03]    [1.52e+00, 1.82e+00, 1.98e-03]    []  
4000      [9.00e-01, 1.11e+00, 2.47e-03]    [6.41e-01, 1.11e+00, 2.47e-03]    []  
6000      [3.04e-01, 5.23e-01, 6.86e-03]    [2.17e-01, 5.23e-01, 6.86e-03]    []  
8000      [9.71e-02, 1.16e-01, 1.70e-02]    [6.20e-02, 1.16e-01, 1.70e-02]    []  
10000     [2.36e-02, 4.68e-03, 2.76e-02]    [2.16e-02, 4.68e-03, 2.76e-02]    []  
12000     [7.19e-03, 9.66e-04, 2.80e-02]    [7.35e-03, 9.66e-04, 2.80e-02]    []  
14000     [2.03e-03, 4.87e-04, 2.68e-02]    [1.81e-03, 4.87e-04, 2.68e-02]    []  
16000     [8.19e-04, 5.28e-04, 2.61e-02]    [7.54e-04, 5.28e-04, 2.61e-02]    []  
18000     [5.09e-04, 4.85e-04, 2.58e-02]    [5.95e-04, 4.85e-04, 2.58e-02]    []  
20000     [3.75e-04, 4.83e-04, 2.56e-02]    [4.93e-04, 4.83e-04, 2.56e-02]    []  

Best model at step 20000:
  train loss: 2.64e-02
  test loss: 2.66e-02
  test metric: []

'train' took 92.625397 s

5 it number
learning rate: 5.4e-02
num_dense_layers: 9
num_dense_nodes: 30
activation: sigmoid
lamda: 0.024761808027681763

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.102188 s

'compile' took 43.490904 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [1.19e-12, 1.40e+00, 2.57e-03]    [1.15e-12, 1.40e+00, 2.57e-03]    []  
2000      [4.35e-17, 8.41e-04, 3.65e-02]    [3.63e-17, 8.41e-04, 3.65e-02]    []  
4000      [7.05e-13, 8.40e-04, 3.65e-02]    [4.22e-13, 8.40e-04, 3.65e-02]    []  
Epoch 4000: early stopping

Best model at step 2000:
  train loss: 3.74e-02
  test loss: 3.74e-02
  test metric: []

'train' took 117.577247 s

6 it number
learning rate: 4.7e-03
num_dense_layers: 6
num_dense_nodes: 24
activation: sin
lamda: 0.027247850801547492

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.071486 s

'compile' took 28.731655 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [3.36e-01, 3.44e-01, 4.23e-03]    [4.43e-01, 3.44e-01, 4.23e-03]    []  
2000      [1.63e-03, 1.18e-03, 4.88e-03]    [2.14e-03, 1.18e-03, 4.88e-03]    []  
4000      [2.19e-03, 3.84e-04, 3.72e-03]    [9.25e-04, 3.82e-04, 3.73e-03]    []  
6000      [1.25e-03, 3.30e-04, 3.78e-03]    [6.64e-04, 3.34e-04, 3.77e-03]    []  
8000      [1.08e-03, 3.29e-04, 3.60e-03]    [4.77e-04, 3.25e-04, 3.61e-03]    []  
10000     [8.50e-04, 1.72e-03, 3.58e-02]    [1.11e-03, 1.72e-03, 3.58e-02]    []  
Epoch 10000: early stopping

Best model at step 8000:
  train loss: 5.01e-03
  test loss: 4.41e-03
  test metric: []

'train' took 90.769620 s

7 it number
learning rate: 1.3e-02
num_dense_layers: 10
num_dense_nodes: 2
activation: sin
lamda: 0.02901192881449209

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.111609 s

'compile' took 48.944938 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [4.63e+05, 1.10e+00, 5.80e-03]    [2.43e+05, 1.10e+00, 5.80e-03]    []  
2000      [9.27e-02, 9.69e-04, 4.27e-02]    [3.85e-02, 9.69e-04, 4.27e-02]    []  
4000      [5.27e-02, 1.06e-03, 4.26e-02]    [2.35e-02, 1.06e-03, 4.26e-02]    []  
6000      [1.98e-02, 1.11e-03, 4.25e-02]    [9.23e-03, 1.11e-03, 4.25e-02]    []  
8000      [5.29e-03, 1.14e-03, 4.25e-02]    [2.88e-03, 1.14e-03, 4.25e-02]    []  
10000     [1.66e-03, 1.18e-03, 4.25e-02]    [1.15e-03, 1.18e-03, 4.25e-02]    []  
12000     [8.04e-04, 1.19e-03, 4.24e-02]    [6.41e-04, 1.19e-03, 4.24e-02]    []  
14000     [3.06e-04, 1.14e-03, 4.25e-02]    [2.83e-04, 1.14e-03, 4.25e-02]    []  
16000     [8.82e-05, 1.14e-03, 4.25e-02]    [9.72e-05, 1.14e-03, 4.25e-02]    []  
18000     [1.93e-05, 1.15e-03, 4.25e-02]    [2.29e-05, 1.15e-03, 4.25e-02]    []  
20000     [2.69e-06, 1.14e-03, 4.25e-02]    [3.30e-06, 1.14e-03, 4.25e-02]    []  

Best model at step 20000:
  train loss: 4.36e-02
  test loss: 4.36e-02
  test metric: []

'train' took 220.279949 s

8 it number
learning rate: 2.5e-03
num_dense_layers: 4
num_dense_nodes: 25
activation: sin
lamda: 0.011153893091407734

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.055543 s

'compile' took 21.520160 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [4.41e-01, 4.19e-01, 2.18e-03]    [4.37e-01, 4.19e-01, 2.18e-03]    []  
2000      [1.29e-03, 5.13e-04, 1.86e-03]    [1.17e-03, 5.13e-04, 1.86e-03]    []  
4000      [3.23e-04, 9.28e-05, 1.67e-03]    [3.49e-04, 9.28e-05, 1.67e-03]    []  
6000      [5.43e-05, 6.95e-05, 1.60e-03]    [9.63e-05, 6.95e-05, 1.60e-03]    []  
8000      [1.36e-04, 9.54e-05, 1.58e-03]    [1.17e-04, 9.54e-05, 1.58e-03]    []  
Epoch 8000: early stopping

Best model at step 6000:
  train loss: 1.73e-03
  test loss: 1.77e-03
  test metric: []

'train' took 70.236361 s

9 it number
learning rate: 4.8e-01
num_dense_layers: 7
num_dense_nodes: 28
activation: tanh
lamda: 0.09447169863034377

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.079690 s

'compile' took 29.074172 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [8.99e-01, 2.21e+00, 1.36e-02]    [8.39e-01, 2.21e+00, 1.36e-02]    []  
2000      [nan, nan, nan]                   [nan, nan, nan]                   []  

Best model at step 0:
  train loss: 3.12e+00
  test loss: 3.06e+00
  test metric: []

'train' took 86.372622 s

10 it number
learning rate: 2.9e-03
num_dense_layers: 3
num_dense_nodes: 13
activation: tanh
lamda: 0.03978604897061095

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.042370 s

'compile' took 13.267144 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [5.52e-01, 1.87e+00, 5.89e-03]    [2.58e-01, 1.87e+00, 5.89e-03]    []  
2000      [1.42e-03, 2.42e-03, 6.54e-03]    [1.86e-03, 2.42e-03, 6.54e-03]    []  
4000      [4.24e-04, 5.34e-04, 5.19e-03]    [5.21e-04, 5.34e-04, 5.19e-03]    []  
6000      [4.23e-04, 3.96e-04, 5.31e-03]    [2.81e-04, 3.96e-04, 5.31e-03]    []  
8000      [2.04e-04, 3.98e-04, 5.31e-03]    [2.05e-04, 3.98e-04, 5.31e-03]    []  
10000     [3.74e-04, 3.57e-04, 5.26e-03]    [3.58e-04, 3.57e-04, 5.26e-03]    []  
Epoch 10000: early stopping

Best model at step 8000:
  train loss: 5.91e-03
  test loss: 5.92e-03
  test metric: []

'train' took 66.862910 s

11 it number
learning rate: 3.2e-02
num_dense_layers: 1
num_dense_nodes: 30
activation: sigmoid
lamda: 0.1

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.022679 s

'compile' took 5.743182 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [2.49e-02, 2.33e+00, 2.79e-02]    [2.31e-02, 2.33e+00, 2.79e-02]    []  
2000      [1.12e-02, 3.37e-03, 1.10e-02]    [5.10e-03, 3.37e-03, 1.10e-02]    []  
4000      [2.84e-04, 1.53e-03, 1.15e-02]    [5.66e-04, 1.53e-03, 1.15e-02]    []  
6000      [7.72e-04, 1.31e-03, 1.16e-02]    [7.57e-04, 1.31e-03, 1.16e-02]    []  
Epoch 6000: early stopping

Best model at step 4000:
  train loss: 1.33e-02
  test loss: 1.36e-02
  test metric: []

'train' took 41.570653 s

12 it number
learning rate: 9.0e-04
num_dense_layers: 10
num_dense_nodes: 1
activation: sigmoid
lamda: 0.1

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.105721 s

'compile' took 62.259209 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [5.78e-17, 2.74e+00, 3.11e-02]    [4.08e-17, 2.74e+00, 3.11e-02]    []  
2000      [4.18e-18, 2.67e-02, 1.18e-01]    [1.97e-18, 2.67e-02, 1.18e-01]    []  
4000      [4.07e-18, 1.19e-02, 1.29e-01]    [1.90e-18, 1.19e-02, 1.29e-01]    []  
6000      [7.95e-18, 1.19e-02, 1.29e-01]    [3.68e-18, 1.19e-02, 1.29e-01]    []  
Epoch 6000: early stopping

Best model at step 4000:
  train loss: 1.41e-01
  test loss: 1.41e-01
  test metric: []

'train' took 139.925902 s

13 it number
learning rate: 4.2e-02
num_dense_layers: 10
num_dense_nodes: 1
activation: sigmoid
lamda: 0.01

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.116194 s

'compile' took 57.518081 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [6.75e-19, 2.69e+00, 2.98e-03]    [5.06e-19, 2.69e+00, 2.98e-03]    []  
2000      [2.94e-23, 1.41e-04, 1.52e-02]    [1.42e-23, 1.41e-04, 1.52e-02]    []  
4000      [2.97e-23, 1.41e-04, 1.52e-02]    [1.44e-23, 1.41e-04, 1.52e-02]    []  
Epoch 4000: early stopping

Best model at step 4000:
  train loss: 1.53e-02
  test loss: 1.53e-02
  test metric: []

'train' took 143.610610 s

14 it number
learning rate: 6.0e-03
num_dense_layers: 2
num_dense_nodes: 19
activation: sigmoid
lamda: 0.05099111561396138

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.047138 s

'compile' took 12.789986 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [2.63e-05, 2.55e+00, 1.45e-02]    [2.85e-05, 2.55e+00, 1.45e-02]    []  
2000      [7.63e-04, 7.37e-03, 3.25e-02]    [1.58e-03, 7.37e-03, 3.25e-02]    []  
4000      [2.83e-04, 3.68e-04, 7.04e-03]    [3.63e-04, 3.68e-04, 7.04e-03]    []  
6000      [6.31e-04, 3.09e-04, 7.02e-03]    [7.41e-04, 3.09e-04, 7.02e-03]    []  
Epoch 6000: early stopping

Best model at step 4000:
  train loss: 7.69e-03
  test loss: 7.77e-03
  test metric: []

'train' took 67.806234 s

[0.002469218272788538, 4, 25, 'sin', 0.011153893091407734]
