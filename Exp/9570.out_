hendrixgpu02fl.unicph.domain
0
0 it number
learning rate: 1.0e-02
num_dense_layers: 1
num_dense_nodes: 10
activation: sigmoid
lamda: 0.1

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.025423 s

'compile' took 2.789307 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [8.38e-03, 9.17e-01, 1.26e-02]    [7.33e-03, 9.17e-01, 1.26e-02]    []  
2000      [2.76e-03, 3.70e-03, 1.74e-02]    [3.76e-03, 3.70e-03, 1.74e-02]    []  
4000      [2.27e-03, 1.05e-03, 1.32e-02]    [2.33e-03, 1.05e-03, 1.32e-02]    []  
6000      [1.58e-03, 6.91e-04, 1.33e-02]    [1.19e-03, 6.91e-04, 1.33e-02]    []  
8000      [6.77e-04, 6.94e-04, 1.33e-02]    [6.59e-04, 6.94e-04, 1.33e-02]    []  
10000     [4.62e-04, 8.00e-04, 1.31e-02]    [5.71e-04, 8.00e-04, 1.31e-02]    []  
12000     [4.00e-04, 8.02e-04, 1.31e-02]    [6.58e-04, 8.02e-04, 1.31e-02]    []  
14000     [2.07e-04, 8.69e-04, 1.30e-02]    [3.96e-04, 8.69e-04, 1.30e-02]    []  
16000     [3.72e-04, 9.27e-04, 1.29e-02]    [6.05e-04, 9.27e-04, 1.29e-02]    []  
Epoch 16000: early stopping

Best model at step 14000:
  train loss: 1.40e-02
  test loss: 1.42e-02
  test metric: []

'train' took 10.025581 s

1 it number
learning rate: 6.9e-03
num_dense_layers: 8
num_dense_nodes: 19
activation: tanh
lamda: 0.07255540512037871

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.081123 s

'compile' took 29.671501 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [7.14e-01, 1.23e+00, 1.04e-02]    [1.71e+00, 1.23e+00, 1.04e-02]    []  
2000      [1.94e-06, 3.54e-03, 1.02e-01]    [2.25e-06, 3.54e-03, 1.02e-01]    []  
4000      [5.92e-11, 6.59e-03, 9.83e-02]    [1.48e-11, 6.59e-03, 9.83e-02]    []  
6000      [5.38e-03, 9.10e-03, 7.93e-02]    [1.01e-02, 9.10e-03, 7.93e-02]    []  
8000      [2.94e-08, 6.59e-03, 9.83e-02]    [1.01e-08, 6.59e-03, 9.83e-02]    []  
Epoch 8000: early stopping

Best model at step 6000:
  train loss: 9.38e-02
  test loss: 9.85e-02
  test metric: []

'train' took 96.620678 s

2 it number
learning rate: 3.6e-04
num_dense_layers: 3
num_dense_nodes: 25
activation: sigmoid
lamda: 0.013065854800735549

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.041070 s

'compile' took 12.665064 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [7.34e-05, 2.61e+00, 3.67e-03]    [7.33e-05, 2.61e+00, 3.67e-03]    []  
2000      [5.77e-05, 4.13e-04, 1.91e-02]    [5.15e-05, 4.13e-04, 1.91e-02]    []  
4000      [7.86e-05, 4.75e-04, 1.90e-02]    [6.95e-05, 4.75e-04, 1.90e-02]    []  
6000      [8.36e-05, 4.88e-04, 1.90e-02]    [7.30e-05, 4.88e-04, 1.90e-02]    []  
8000      [8.69e-05, 4.88e-04, 1.90e-02]    [7.17e-05, 4.88e-04, 1.90e-02]    []  
10000     [1.44e-04, 4.95e-04, 1.88e-02]    [1.15e-04, 4.95e-04, 1.88e-02]    []  
12000     [4.41e-04, 1.12e-03, 8.76e-03]    [1.21e-03, 1.12e-03, 8.76e-03]    []  
14000     [4.12e-04, 3.77e-04, 2.28e-03]    [1.12e-03, 3.77e-04, 2.28e-03]    []  
16000     [2.48e-04, 1.73e-04, 1.94e-03]    [6.64e-04, 1.73e-04, 1.94e-03]    []  
18000     [1.34e-04, 1.07e-04, 1.87e-03]    [3.78e-04, 1.07e-04, 1.87e-03]    []  
20000     [1.02e-04, 8.32e-05, 1.86e-03]    [2.79e-04, 8.32e-05, 1.86e-03]    []  

Best model at step 20000:
  train loss: 2.05e-03
  test loss: 2.22e-03
  test metric: []

'train' took 58.988863 s

3 it number
learning rate: 1.1e-04
num_dense_layers: 5
num_dense_nodes: 11
activation: tanh
lamda: 0.012538683368444242

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.055948 s

'compile' took 18.462350 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [1.34e+01, 1.30e+00, 3.22e-03]    [7.68e+00, 1.30e+00, 3.22e-03]    []  
2000      [7.04e-03, 2.19e-03, 1.90e-02]    [4.43e-03, 2.19e-03, 1.90e-02]    []  
4000      [9.31e-04, 5.61e-04, 1.89e-02]    [1.05e-03, 5.61e-04, 1.89e-02]    []  
6000      [3.13e-04, 4.07e-04, 1.86e-02]    [5.62e-04, 4.07e-04, 1.86e-02]    []  
8000      [2.25e-04, 3.97e-04, 1.84e-02]    [2.36e-04, 3.97e-04, 1.84e-02]    []  
10000     [2.00e-04, 3.90e-04, 1.81e-02]    [1.57e-04, 3.90e-04, 1.81e-02]    []  
12000     [2.52e-04, 4.23e-04, 1.75e-02]    [3.04e-04, 4.23e-04, 1.75e-02]    []  
14000     [6.54e-04, 8.24e-04, 5.46e-03]    [1.29e-03, 8.24e-04, 5.46e-03]    []  
16000     [4.66e-04, 4.84e-04, 2.30e-03]    [9.91e-04, 4.84e-04, 2.30e-03]    []  
18000     [3.58e-04, 2.73e-04, 1.87e-03]    [8.44e-04, 2.73e-04, 1.87e-03]    []  
20000     [3.16e-04, 1.98e-04, 1.79e-03]    [7.69e-04, 1.98e-04, 1.79e-03]    []  

Best model at step 20000:
  train loss: 2.30e-03
  test loss: 2.76e-03
  test metric: []

'train' took 93.519536 s

4 it number
learning rate: 1.6e-04
num_dense_layers: 5
num_dense_nodes: 2
activation: sin
lamda: 0.017635770689809285

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.061168 s

'compile' took 21.744610 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [6.73e+02, 1.64e+00, 5.26e-03]    [3.78e+02, 1.64e+00, 5.26e-03]    []  
2000      [3.16e+00, 1.82e+00, 1.98e-03]    [1.52e+00, 1.82e+00, 1.98e-03]    []  
4000      [9.00e-01, 1.11e+00, 2.47e-03]    [6.41e-01, 1.11e+00, 2.47e-03]    []  
6000      [3.04e-01, 5.23e-01, 6.86e-03]    [2.17e-01, 5.23e-01, 6.86e-03]    []  
8000      [9.71e-02, 1.16e-01, 1.70e-02]    [6.20e-02, 1.16e-01, 1.70e-02]    []  
10000     [2.36e-02, 4.68e-03, 2.76e-02]    [2.16e-02, 4.68e-03, 2.76e-02]    []  
12000     [7.19e-03, 9.66e-04, 2.80e-02]    [7.35e-03, 9.66e-04, 2.80e-02]    []  
14000     [2.03e-03, 4.87e-04, 2.68e-02]    [1.81e-03, 4.87e-04, 2.68e-02]    []  
16000     [8.19e-04, 5.28e-04, 2.61e-02]    [7.54e-04, 5.28e-04, 2.61e-02]    []  
18000     [5.09e-04, 4.85e-04, 2.58e-02]    [5.95e-04, 4.85e-04, 2.58e-02]    []  
20000     [3.75e-04, 4.83e-04, 2.56e-02]    [4.93e-04, 4.83e-04, 2.56e-02]    []  

Best model at step 20000:
  train loss: 2.64e-02
  test loss: 2.66e-02
  test metric: []

'train' took 92.625397 s

5 it number
learning rate: 5.4e-02
num_dense_layers: 9
num_dense_nodes: 30
activation: sigmoid
lamda: 0.024761808027681763

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.102188 s

'compile' took 43.490904 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [1.19e-12, 1.40e+00, 2.57e-03]    [1.15e-12, 1.40e+00, 2.57e-03]    []  
2000      [4.35e-17, 8.41e-04, 3.65e-02]    [3.63e-17, 8.41e-04, 3.65e-02]    []  
