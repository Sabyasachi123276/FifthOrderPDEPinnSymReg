hendrixgpu14fl.unicph.domain
0
0 it number
learning rate: 1.0e-02
num_dense_layers: 1
num_dense_nodes: 10
activation: sigmoid
lamda: 0.1

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.032163 s

'compile' took 3.292797 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [6.28e-04, 1.42e-01, 1.34e-02]    [6.08e-04, 1.42e-01, 1.34e-02]    []  
2000      [9.49e-05, 3.47e-05, 7.48e-03]    [1.75e-04, 3.47e-05, 7.48e-03]    []  
4000      [3.84e-05, 5.40e-05, 6.96e-03]    [3.44e-05, 5.40e-05, 6.96e-03]    []  
6000      [2.57e-05, 6.37e-05, 6.92e-03]    [3.26e-05, 6.37e-05, 6.92e-03]    []  
8000      [3.94e-05, 6.67e-05, 6.91e-03]    [6.29e-05, 6.67e-05, 6.91e-03]    []  
Epoch 8000: early stopping

Best model at step 6000:
  train loss: 7.01e-03
  test loss: 7.02e-03
  test metric: []

'train' took 8.642618 s

1 it number
learning rate: 6.9e-03
num_dense_layers: 8
num_dense_nodes: 19
activation: tanh
lamda: 0.07255540512037871

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.109643 s

'compile' took 25.660273 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [1.05e+01, 1.59e-01, 1.81e-02]    [4.61e+00, 1.59e-01, 1.81e-02]    []  
2000      [1.18e-04, 3.45e-05, 5.24e-03]    [8.37e-05, 3.45e-05, 5.24e-03]    []  
4000      [9.44e-05, 4.28e-04, 7.67e-03]    [1.84e-04, 4.28e-04, 7.67e-03]    []  
Epoch 4000: early stopping

Best model at step 2000:
  train loss: 5.39e-03
  test loss: 5.36e-03
  test metric: []

'train' took 70.651311 s

2 it number
learning rate: 3.6e-04
num_dense_layers: 3
num_dense_nodes: 25
activation: sigmoid
lamda: 0.013065854800735549

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.054392 s

'compile' took 11.285695 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [2.81e-04, 6.77e-03, 1.59e-03]    [2.71e-04, 6.77e-03, 1.59e-03]    []  
2000      [3.58e-06, 7.83e-06, 1.85e-03]    [3.12e-06, 7.83e-06, 1.85e-03]    []  
4000      [5.88e-06, 8.16e-06, 1.83e-03]    [7.16e-06, 8.16e-06, 1.83e-03]    []  
6000      [1.75e-05, 9.17e-06, 1.05e-03]    [2.07e-05, 9.17e-06, 1.05e-03]    []  
8000      [1.14e-05, 4.01e-06, 9.31e-04]    [1.27e-05, 4.01e-06, 9.31e-04]    []  
10000     [9.61e-06, 2.51e-06, 9.26e-04]    [8.69e-06, 2.51e-06, 9.26e-04]    []  
12000     [2.68e-06, 2.18e-06, 9.25e-04]    [3.45e-06, 2.18e-06, 9.25e-04]    []  
14000     [2.82e-06, 1.78e-06, 9.25e-04]    [2.71e-06, 1.78e-06, 9.25e-04]    []  
Epoch 14000: early stopping

Best model at step 14000:
  train loss: 9.29e-04
  test loss: 9.29e-04
  test metric: []

'train' took 46.117660 s

3 it number
learning rate: 1.1e-04
num_dense_layers: 5
num_dense_nodes: 11
activation: tanh
lamda: 0.012538683368444242

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.079966 s

'compile' took 17.073674 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [9.78e+00, 2.30e-01, 2.11e-03]    [2.00e+01, 2.30e-01, 2.11e-03]    []  
2000      [4.70e-03, 1.40e-03, 1.75e-03]    [5.53e-03, 1.40e-03, 1.75e-03]    []  
4000      [6.98e-04, 3.05e-04, 1.82e-03]    [8.14e-04, 3.05e-04, 1.82e-03]    []  
6000      [2.55e-04, 8.01e-05, 1.78e-03]    [3.49e-04, 8.01e-05, 1.78e-03]    []  
8000      [9.06e-05, 3.11e-05, 1.77e-03]    [1.41e-04, 3.11e-05, 1.77e-03]    []  
10000     [3.59e-05, 1.82e-05, 1.77e-03]    [7.14e-05, 1.82e-05, 1.77e-03]    []  
12000     [1.68e-05, 1.42e-05, 1.77e-03]    [3.61e-05, 1.42e-05, 1.77e-03]    []  
14000     [1.08e-05, 1.28e-05, 1.77e-03]    [2.21e-05, 1.28e-05, 1.77e-03]    []  
16000     [9.24e-06, 1.35e-05, 1.75e-03]    [1.85e-05, 1.35e-05, 1.75e-03]    []  
18000     [1.06e-05, 1.44e-05, 1.71e-03]    [1.75e-05, 1.44e-05, 1.71e-03]    []  
20000     [2.10e-05, 2.14e-05, 1.52e-03]    [1.86e-05, 2.14e-05, 1.52e-03]    []  

Best model at step 20000:
  train loss: 1.57e-03
  test loss: 1.56e-03
  test metric: []

'train' took 89.672972 s

4 it number
learning rate: 1.6e-04
num_dense_layers: 5
num_dense_nodes: 2
activation: sin
lamda: 0.017635770689809285

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.081660 s

'compile' took 18.535611 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [1.62e-01, 9.79e-02, 3.02e-03]    [1.06e-01, 9.79e-02, 3.02e-03]    []  
2000      [1.49e-03, 1.59e-03, 2.53e-03]    [1.77e-03, 1.59e-03, 2.53e-03]    []  
4000      [3.23e-04, 1.14e-04, 2.49e-03]    [5.14e-04, 1.14e-04, 2.49e-03]    []  
6000      [1.00e-04, 2.06e-05, 2.48e-03]    [1.61e-04, 2.06e-05, 2.48e-03]    []  
8000      [4.42e-05, 1.58e-05, 2.48e-03]    [6.26e-05, 1.58e-05, 2.48e-03]    []  
10000     [2.08e-05, 1.54e-05, 2.48e-03]    [2.92e-05, 1.54e-05, 2.48e-03]    []  
12000     [1.27e-05, 1.56e-05, 2.48e-03]    [1.75e-05, 1.56e-05, 2.48e-03]    []  
14000     [9.82e-06, 1.55e-05, 2.48e-03]    [1.34e-05, 1.55e-05, 2.48e-03]    []  
16000     [9.36e-06, 1.43e-05, 2.49e-03]    [1.25e-05, 1.43e-05, 2.49e-03]    []  
Epoch 16000: early stopping

Best model at step 16000:
  train loss: 2.51e-03
  test loss: 2.51e-03
  test metric: []

'train' took 80.421041 s

5 it number
learning rate: 5.4e-02
num_dense_layers: 9
num_dense_nodes: 30
activation: sigmoid
lamda: 0.024761808027681763

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.130526 s

'compile' took 37.302542 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [6.14e-13, 4.37e-02, 6.71e-03]    [5.77e-13, 4.37e-02, 6.71e-03]    []  
2000      [1.99e-21, 2.34e-05, 3.51e-03]    [1.47e-21, 2.34e-05, 3.51e-03]    []  
4000      [1.70e-21, 2.34e-05, 3.51e-03]    [1.24e-21, 2.34e-05, 3.51e-03]    []  
Epoch 4000: early stopping

Best model at step 2000:
  train loss: 3.53e-03
  test loss: 3.53e-03
  test metric: []

'train' took 104.257839 s

6 it number
learning rate: 4.7e-03
num_dense_layers: 6
num_dense_nodes: 24
activation: sin
lamda: 0.027247850801547492

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.093951 s

'compile' took 24.406145 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [4.16e-02, 6.24e-02, 3.99e-03]    [3.48e-02, 6.25e-02, 3.99e-03]    []  
2000      [6.77e-05, 2.71e-05, 2.52e-03]    [6.37e-05, 2.68e-05, 2.52e-03]    []  
4000      [1.38e-05, 2.58e-05, 1.94e-03]    [1.91e-05, 2.66e-05, 1.94e-03]    []  
6000      [1.21e-05, 4.12e-05, 3.50e-03]    [1.50e-05, 4.13e-05, 3.50e-03]    []  
Epoch 6000: early stopping

Best model at step 4000:
  train loss: 1.98e-03
  test loss: 1.99e-03
  test metric: []

'train' took 71.545748 s

7 it number
learning rate: 1.3e-02
num_dense_layers: 10
num_dense_nodes: 2
activation: sin
lamda: 0.02901192881449209

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.145344 s

'compile' took 42.022451 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [1.28e+03, 4.77e-02, 5.08e-03]    [1.34e+03, 4.77e-02, 5.08e-03]    []  
2000      [5.73e-04, 3.24e-05, 4.11e-03]    [6.29e-04, 3.24e-05, 4.11e-03]    []  
4000      [1.22e-04, 3.27e-05, 4.10e-03]    [1.33e-04, 3.27e-05, 4.10e-03]    []  
6000      [5.41e-06, 3.19e-05, 4.10e-03]    [5.08e-06, 3.19e-05, 4.10e-03]    []  
8000      [5.21e-06, 3.22e-05, 4.10e-03]    [4.88e-06, 3.22e-05, 4.10e-03]    []  
Epoch 8000: early stopping

Best model at step 8000:
  train loss: 4.14e-03
  test loss: 4.14e-03
  test metric: []

'train' took 135.738286 s

8 it number
learning rate: 2.5e-03
num_dense_layers: 4
num_dense_nodes: 25
activation: sin
lamda: 0.011153893091407734

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.072895 s

'compile' took 19.986546 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [1.26e-02, 7.58e-02, 2.00e-03]    [7.90e-03, 7.58e-02, 2.00e-03]    []  
2000      [7.73e-06, 3.75e-06, 8.03e-04]    [1.80e-05, 3.75e-06, 8.03e-04]    []  
4000      [1.32e-05, 2.45e-05, 7.96e-04]    [1.06e-05, 2.45e-05, 7.96e-04]    []  
Epoch 4000: early stopping

Best model at step 2000:
  train loss: 8.14e-04
  test loss: 8.25e-04
  test metric: []

'train' took 56.327445 s

9 it number
learning rate: 4.8e-01
num_dense_layers: 7
num_dense_nodes: 28
activation: tanh
lamda: 0.09447169863034377

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.129437 s

'compile' took 24.745369 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [2.24e-02, 5.09e-03, 1.37e-02]    [2.14e-02, 5.09e-03, 1.37e-02]    []  
2000      [nan, nan, nan]                   [nan, nan, nan]                   []  

Best model at step 0:
  train loss: 4.12e-02
  test loss: 4.02e-02
  test metric: []

'train' took 77.072895 s

10 it number
learning rate: 2.9e-03
num_dense_layers: 3
num_dense_nodes: 13
activation: tanh
lamda: 0.03978604897061095

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.059980 s

'compile' took 12.003013 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [3.90e-01, 3.55e-01, 6.74e-03]    [3.18e-01, 3.55e-01, 6.74e-03]    []  
2000      [7.00e-05, 7.79e-05, 4.24e-03]    [1.17e-04, 7.79e-05, 4.24e-03]    []  
4000      [1.01e-05, 2.70e-05, 2.78e-03]    [1.02e-05, 2.70e-05, 2.78e-03]    []  
6000      [1.87e-05, 8.23e-05, 2.76e-03]    [1.65e-05, 8.23e-05, 2.76e-03]    []  
Epoch 6000: early stopping

Best model at step 4000:
  train loss: 2.82e-03
  test loss: 2.82e-03
  test metric: []

'train' took 53.796529 s

11 it number
learning rate: 3.2e-02
num_dense_layers: 1
num_dense_nodes: 30
activation: sigmoid
lamda: 0.1

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.030076 s

'compile' took 5.683693 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [7.83e-03, 1.83e-01, 3.50e-02]    [6.81e-03, 1.83e-01, 3.50e-02]    []  
2000      [3.13e-05, 1.54e-04, 6.79e-03]    [4.52e-05, 1.54e-04, 6.79e-03]    []  
4000      [2.45e-05, 1.48e-04, 6.70e-03]    [4.12e-05, 1.48e-04, 6.70e-03]    []  
6000      [2.27e-05, 1.68e-04, 6.60e-03]    [6.50e-05, 1.68e-04, 6.60e-03]    []  
8000      [2.48e-05, 2.09e-04, 6.50e-03]    [4.84e-05, 2.09e-04, 6.50e-03]    []  
10000     [3.13e-05, 1.73e-04, 6.47e-03]    [4.40e-05, 1.73e-04, 6.47e-03]    []  
12000     [3.91e-05, 2.05e-04, 6.39e-03]    [4.72e-05, 2.05e-04, 6.39e-03]    []  
14000     [1.57e-04, 2.26e-04, 6.46e-03]    [6.14e-05, 2.26e-04, 6.46e-03]    []  
Epoch 14000: early stopping

Best model at step 12000:
  train loss: 6.64e-03
  test loss: 6.65e-03
  test metric: []

'train' took 43.564142 s

12 it number
learning rate: 9.0e-04
num_dense_layers: 10
num_dense_nodes: 1
activation: sigmoid
lamda: 0.1

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.172410 s

'compile' took 56.551022 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [3.09e-16, 3.56e-01, 2.61e-02]    [3.97e-16, 3.56e-01, 2.61e-02]    []  
2000      [4.56e-18, 3.31e-04, 1.37e-02]    [4.66e-18, 3.31e-04, 1.37e-02]    []  
4000      [7.22e-18, 3.31e-04, 1.37e-02]    [7.42e-18, 3.31e-04, 1.37e-02]    []  
Epoch 4000: early stopping

Best model at step 2000:
  train loss: 1.40e-02
  test loss: 1.40e-02
  test metric: []

'train' took 116.940777 s

13 it number
learning rate: 4.2e-02
num_dense_layers: 10
num_dense_nodes: 1
activation: sigmoid
lamda: 0.01

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.158035 s

'compile' took 49.869627 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [5.55e-19, 4.92e-03, 1.21e-03]    [5.91e-19, 4.92e-03, 1.21e-03]    []  
2000      [2.10e-20, 3.92e-06, 1.43e-03]    [2.16e-20, 3.92e-06, 1.43e-03]    []  
4000      [3.87e-19, 3.92e-06, 1.43e-03]    [3.99e-19, 3.92e-06, 1.43e-03]    []  
Epoch 4000: early stopping

Best model at step 2000:
  train loss: 1.43e-03
  test loss: 1.43e-03
  test metric: []

'train' took 122.866504 s

14 it number
learning rate: 6.0e-03
num_dense_layers: 2
num_dense_nodes: 19
activation: sigmoid
lamda: 0.05099111561396138

Warning: 200 points required, but 210 points sampled.
Compiling model...
Building feed-forward neural network...
'build' took 0.054497 s

'compile' took 11.320238 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [2.16e-04, 5.22e-02, 5.38e-03]    [2.11e-04, 5.22e-02, 5.38e-03]    []  
2000      [4.00e-05, 2.17e-05, 3.57e-03]    [7.33e-05, 2.17e-05, 3.57e-03]    []  
4000      [1.60e-05, 1.82e-05, 3.56e-03]    [2.13e-05, 1.82e-05, 3.56e-03]    []  
6000      [1.80e-05, 2.52e-05, 3.54e-03]    [2.03e-05, 2.52e-05, 3.54e-03]    []  
8000      [1.76e-05, 3.17e-05, 3.53e-03]    [2.05e-05, 3.17e-05, 3.53e-03]    []  
10000     [9.12e-06, 3.96e-05, 3.52e-03]    [1.48e-05, 3.96e-05, 3.52e-03]    []  
12000     [7.57e-06, 8.06e-05, 3.49e-03]    [1.45e-05, 8.06e-05, 3.49e-03]    []  
Epoch 12000: early stopping

Best model at step 10000:
  train loss: 3.56e-03
  test loss: 3.57e-03
  test metric: []

'train' took 64.617973 s

[0.002469218272788538, 4, 25, 'sin', 0.011153893091407734]
